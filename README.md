# 🕵️ AI 힌트 추리 게임 - 정체를 밝혀라!

AI가 한 인물을 정하고, 사용자는 제한된 질문을 통해 그 정체를 맞추는 Streamlit 기반 인터랙티브 게임입니다.

---

## ✨ 주요 기능

- 사용자는 최대 **10개의 질문**을 통해 인물을 유추
- AI는 질문에 대해 **힌트를 제공**, 단 정답을 직접 말하지 않음
- 사용자가 **정확히 이름을 말할 경우**에만 “정답이야!” 응답
- 10개 질문 이후에도 못 맞히면, AI가 **정답 공개**
- 질문 수 카운트, 힌트 강도 조절, 분야 선택 가능

---

## 🧱 기술 구성

- **프론트엔드**: Streamlit
- **백엔드 모델**: Ollama + EEVE-Korean-10.8B
- **배포 환경**: RunPod PyTorch + Jupyter 환경

---

## 🛠️ 실행 순서

### 1. RunPod에서 Pod 생성
- 템플릿: `RunPod Pytorch 2.1.1 + Jupyter`
- 설정 완료 후 Web Terminal 접속

### 2. Ollama 설치 및 서버 실행
```bash
curl -fsSL https://ollama.com/install.sh | sh
ollama serve
```

### 3. 모델 다운로드
```bash
ollama pull EEVE-Korean-10.8B
```

### 4. 게임 실행
```bash
streamlit run LLM_game.py --server.address 0.0.0.0 --server.port 8000
```

### 5. 접속 방법
- RunPod가 부여한 외부 IP + 포트 (예: `69.30.xx.xx:22098`)로 접속

---

## 💡 사용 예시

```plaintext
User: 너는 사람이야?
AI: 네, 저는 사람이에요.

User: 너는 정국이야?
AI: 정답이야!

User: 너는 누군데?
AI: 아직 알려줄 수 없어요! 질문을 해보세요~
```

---

## 🧠 AI 응답 방식

- 힌트는 간접적으로 제공하며 정체는 **직접 밝히지 않음**
- "정답이야!" / "아니야!"는 **이름이 정확히 일치할 경우에만 출력**
- 질문 수가 초과되면 자동으로 정답 공개

---

## 🛡️ 주의사항 및 오류 방지

- `ollama serve`는 반드시 백그라운드에서 **실행 중이어야 함**
- 모델명 정확히 입력해야 함: `EEVE-Korean-10.8B`
- 모델 미설치 시 오류 발생 → `ollama pull`로 사전 다운로드 필요

---

## 📎 기타 정보

- 인물은 아이돌, 스포츠 선수, 캐릭터 등 40여 명으로 구성
- 캐릭터 카테고리 **선택 가능**

---

## 🎉 결과 예시

- 질문 10번 내에 맞추면 🎊 축하 메시지와 함께 정답 공개
- 실패 시 ❌ 에러 메시지와 함께 정답 안내

---

